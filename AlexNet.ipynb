{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install piexif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2aCgCnitrz3",
        "outputId": "fb3be4f3-7d31-4f4f-b0dc-be4dd549e6fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting piexif\n",
            "  Downloading piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading piexif-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Installing collected packages: piexif\n",
            "Successfully installed piexif-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "6Eu5LpHGphLG",
        "outputId": "9dff3312-7df9-477f-f1cc-ab978edf473f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-400b6c836750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mAlexnetDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import piexif\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Datalodaer for ImageNet dataset\n",
        "# Expected directory structure:\n",
        "#   -  data_root/\n",
        "#       -  class1/\n",
        "#           - train/\n",
        "#           - test/\n",
        "#           - validation/\n",
        "#       -   class2/\n",
        "#           -...\n",
        "#       -...\n",
        "\n",
        "\n",
        "IMG_EXTENSIONS = [\n",
        "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
        "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
        "]\n",
        "\n",
        "\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
        "\n",
        "\n",
        "def find_classes(dir):\n",
        "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx\n",
        "\n",
        "\n",
        "def make_dataset(dir, phase, class_to_idx):\n",
        "    images = []\n",
        "    dir = os.path.expanduser(dir)\n",
        "    for target in sorted(os.listdir(dir)):\n",
        "        if target not in class_to_idx:\n",
        "            continue\n",
        "        d = os.path.join(dir, target)\n",
        "        d = os.path.join(d, phase)\n",
        "        if not os.path.isdir(d):\n",
        "            continue\n",
        "        for root, _, fnames in sorted(os.walk(d)):\n",
        "            for fname in sorted(fnames):\n",
        "                if not is_image_file(fname):\n",
        "                    continue\n",
        "                path = os.path.join(root, fname)\n",
        "                item = (path, class_to_idx[target])\n",
        "                images.append(item)\n",
        "\n",
        "    return images\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(path, 'rb') as f:\n",
        "        with Image.open(f) as img:\n",
        "            return img.convert('RGB')\n",
        "\n",
        "\n",
        "def accimage_loader(path):\n",
        "    import accimage\n",
        "    try:\n",
        "        return accimage.Image(path)\n",
        "    except IOError:\n",
        "        # Potentially a decoding problem, fall back to PIL.Image\n",
        "        return pil_loader(path)\n",
        "\n",
        "\n",
        "def default_loader(path):\n",
        "    from torchvision import get_image_backend\n",
        "    if get_image_backend() == 'accimage':\n",
        "        return accimage_loader(path)\n",
        "    else:\n",
        "        return pil_loader(path)\n",
        "\n",
        "\n",
        "class AlexnetDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root, phase, transform=None, loader=default_loader):\n",
        "        super(AlexnetDataset, self).__init__()\n",
        "        classes, class_to_idx = find_classes(root)\n",
        "        imgs = make_dataset(root, phase, class_to_idx)\n",
        "        if len(imgs) == 0:\n",
        "            raise(RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n",
        "                               \"Supported image extensions are: \" + \",\".join(IMG_EXTENSIONS)))\n",
        "        self.root = root\n",
        "        self.phase = phase\n",
        "        self.imgs = imgs\n",
        "        self.classes = classes\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "        self.loader = loader\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path, target = self.imgs[index]\n",
        "        img = self.loader(path)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "def remove_exif(dir, phase):\n",
        "    dir = os.path.expanduser(dir)\n",
        "    for target in sorted(os.listdir(dir)):\n",
        "        d = os.path.join(dir, target)\n",
        "        d = os.path.join(d, phase)\n",
        "        if not os.path.isdir(d):\n",
        "            continue\n",
        "        for root, _, fnames in sorted(os.walk(d)):\n",
        "            for fname in sorted(fnames):\n",
        "                if not is_image_file(fname):\n",
        "                    continue\n",
        "                path = os.path.join(root, fname)\n",
        "                try:\n",
        "                    piexif.remove(path)\n",
        "                except:\n",
        "                    print(\"Failed to remove exif for: \" + path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "def __extract_file__(fname):\n",
        "    with open(fname, 'rb') as fo:\n",
        "        d = pickle.load(fo, encoding='bytes')\n",
        "    return d\n"
      ],
      "metadata": {
        "id": "28qwiaRyux-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __extract_file__(fname):\n",
        "    with open(fname, 'rb') as fo:\n",
        "        d = pickle.load(fo, encoding='bytes')\n",
        "    return d\n",
        "\n",
        "\n",
        "def __extract_reshape_file__(fname):\n",
        "    res = []\n",
        "    d = __extract_file__(fname)\n",
        "    images = d[b\"data\"]\n",
        "    labels = d[b\"labels\"]\n",
        "    for image, label in zip(images, labels):\n",
        "        res.append((image, label))\n",
        "    return res"
      ],
      "metadata": {
        "id": "P9wZHFDQuyBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "def __extract_file__(fname):\n",
        "    with open(fname, 'rb') as fo:\n",
        "        d = pickle.load(fo, encoding='bytes')\n",
        "    return d\n",
        "\n",
        "\n",
        "def __unflatten_image__(img_flat):\n",
        "    img_R = img_flat[0:1024].reshape((32, 32))\n",
        "    img_G = img_flat[1024:2048].reshape((32, 32))\n",
        "    img_B = img_flat[2048:3072].reshape((32, 32))\n",
        "    img = np.dstack((img_R, img_G, img_B))\n",
        "    return img\n",
        "\n",
        "\n",
        "def __extract_reshape_file__(fname):\n",
        "    res = []\n",
        "    d = __extract_file__(fname)\n",
        "    images = d[b\"data\"]\n",
        "    labels = d[b\"labels\"]\n",
        "    for image, label in zip(images, labels):\n",
        "        res.append((__unflatten_image__(image), label))\n",
        "    return res"
      ],
      "metadata": {
        "id": "L4PlRguhuyFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "QSu4G2O8uyIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ef get_images_from(dir):\n",
        "    files = [f for f in os.listdir(dir) if f.startswith(\"data_batch\")]\n",
        "    res = []\n",
        "    for f in files:\n",
        "        res = res + __extract_reshape_file__(os.path.join(dir, f))\n",
        "    return res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "Hk-BUKteuyKy",
        "outputId": "1838b697-620a-4175-fa02-1194a214d168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-060756274ed2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ef get_images_from(dir):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import math\n",
        "\n",
        "def __extract_file__(fname):\n",
        "    with open(fname, 'rb') as fo:\n",
        "        d = pickle.load(fo, encoding='bytes')\n",
        "    return d\n",
        "\n",
        "\n",
        "def __unflatten_image__(img_flat):\n",
        "    img_R = img_flat[0:1024].reshape((32, 32))\n",
        "    img_G = img_flat[1024:2048].reshape((32, 32))\n",
        "    img_B = img_flat[2048:3072].reshape((32, 32))\n",
        "    img = np.dstack((img_R, img_G, img_B))\n",
        "    return img\n",
        "\n",
        "\n",
        "def __extract_reshape_file__(fname):\n",
        "    res = []\n",
        "    d = __extract_file__(fname)\n",
        "    images = d[b\"data\"]\n",
        "    labels = d[b\"labels\"]\n",
        "    for image, label in zip(images, labels):\n",
        "        res.append((__unflatten_image__(image), label))\n",
        "    return res\n",
        "\n",
        "\n",
        "def get_images_from(dir):\n",
        "    files = [f for f in os.listdir(dir) if f.startswith(\"data_batch\")]\n",
        "    res = []\n",
        "    for f in files:\n",
        "        res = res + __extract_reshape_file__(os.path.join(dir, f))\n",
        "    return res\n",
        "\n",
        "\n",
        "class Cifar(object):\n",
        "\n",
        "    def __init__(self, dir=\"data/cifar-10-batches-py/\", batch_size=1):\n",
        "        self.__res__ = get_images_from(dir)\n",
        "        self.batch_size = batch_size\n",
        "        self.batches = []\n",
        "        self.__batch_num__ = 0\n",
        "        for i in range(math.ceil(len(self.__res__)/batch_size)):\n",
        "            self.batches.append(self.__res__[i*batch_size:(i+1)*batch_size])\n",
        "\n",
        "    def batch(self, num):\n",
        "        return self.batches[num]\n",
        "\n",
        "    def next_batch(self):\n",
        "        if self.__batch_num__ <= len(self.batches):\n",
        "            res = self.batches[self.__batch_num__]\n",
        "            self.__batch_num__ = self.__batch_num__ + 1\n",
        "        else:\n",
        "            res = []\n",
        "\n",
        "        return res\n",
        "\n",
        "    def reset_batch(self):\n",
        "        self.__batch_num__ = 0"
      ],
      "metadata": {
        "id": "iRoIIUouuyNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "image_size = 32\n",
        "input_images = tf.placeholder(tf.float32,\n",
        "                              shape=[None, image_size, image_size, 3],\n",
        "                              name=\"input_images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cVaAkGNuyP1",
        "outputId": "18071126-416c-4f84-ac64-5ffd5c7351a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the first convolutional Layer\n",
        "# First CONV layer\n",
        "#“The first convolutional layer filters the 224×224×3 input image with 96 kernels of size 11×11×3 with a stride of 4 pixels.”[1]\n",
        "#First Convolutional Layer\n",
        "kernel = tf.Variable(tf.truncated_normal([11, 11, 3, 96],\n",
        "                                         dtype=tf.float32,\n",
        "                                         stddev=1e-1),\n",
        "                     name=\"conv1_weights\")\n",
        "conv = tf.nn.conv2d(input_images, kernel, [1, 4, 4, 1], padding=\"SAME\")\n",
        "bias = tf.Variable(tf.truncated_normal([96]))\n",
        "conv_with_bias = tf.nn.bias_add(conv, bias)\n",
        "conv1 = tf.nn.relu(conv_with_bias, name=\"conv1\")\n",
        "\n",
        "lrn1 = tf.nn.lrn(conv1,\n",
        "                 alpha=1e-4,\n",
        "                 beta=0.75,\n",
        "                 depth_radius=2,\n",
        "                 bias=2.0)\n",
        "\n",
        "pooled_conv1 = tf.nn.max_pool(lrn1,\n",
        "                              ksize=[1, 3, 3, 1],\n",
        "                              strides=[1, 2, 2, 1],\n",
        "                              padding=\"SAME\",\n",
        "                              name=\"pool1\")\n",
        "\n",
        "#Second Convolutional Layer\n",
        "\n",
        "kernel = tf.Variable(tf.truncated_normal([5, 5, 96, 256],\n",
        "                                         dtype=tf.float32,\n",
        "                                         stddev=1e-1),\n",
        "                     name=\"conv2_weights\")\n",
        "conv = tf.nn.conv2d(pooled_conv1, kernel, [1, 4, 4, 1], padding=\"SAME\")\n",
        "bias = tf.Variable(tf.truncated_normal([256]), name=\"conv2_bias\")\n",
        "conv_with_bias = tf.nn.bias_add(conv, bias)\n",
        "conv2 = tf.nn.relu(conv_with_bias, name=\"conv2\")\n",
        "lrn2 = tf.nn.lrn(conv2,\n",
        "                 alpha=1e-4,\n",
        "                 beta=0.75,\n",
        "                 depth_radius=2,\n",
        "                 bias=2.0)\n",
        "\n",
        "pooled_conv2 = tf.nn.max_pool(lrn2,\n",
        "                              ksize=[1, 3, 3, 1],\n",
        "                              strides=[1, 2, 2, 1],\n",
        "                              padding=\"SAME\",\n",
        "                              name=\"pool2\")"
      ],
      "metadata": {
        "id": "KTRq_7aDxa_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conv2D"
      ],
      "metadata": {
        "id": "QTNsc4tJxbCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "n_classes = 10 # <-- newly added constant\n",
        "\n",
        "image_size = 32\n",
        "input_images = tf.placeholder(tf.float32,\n",
        "                              shape=[None, image_size, image_size, 3],\n",
        "                              name=\"input_images\")\n",
        "\n",
        "# First CONV layer\n",
        "kernel = tf.Variable(tf.truncated_normal([11, 11, 3, 96],\n",
        "                                         dtype=tf.float32,\n",
        "                                         stddev=1e-1),\n",
        "                     name=\"conv1_weights\")\n",
        "conv = tf.nn.conv2d(input_images, kernel, [1, 4, 4, 1], padding=\"SAME\")\n",
        "bias = tf.Variable(tf.truncated_normal([96]))\n",
        "conv_with_bias = tf.nn.bias_add(conv, bias)\n",
        "conv1 = tf.nn.relu(conv_with_bias, name=\"conv1\")\n",
        "\n",
        "lrn1 = tf.nn.lrn(conv1,\n",
        "                 alpha=1e-4,\n",
        "                 beta=0.75,\n",
        "                 depth_radius=2,\n",
        "                 bias=2.0)\n",
        "\n",
        "pooled_conv1 = tf.nn.max_pool(lrn1,\n",
        "                              ksize=[1, 3, 3, 1],\n",
        "                              strides=[1, 2, 2, 1],\n",
        "                              padding=\"SAME\",\n",
        "                              name=\"pool1\")\n",
        "\n",
        "# Second CONV Layer\n",
        "kernel = tf.Variable(tf.truncated_normal([5, 5, 96, 256],\n",
        "                                         dtype=tf.float32,\n",
        "                                         stddev=1e-1),\n",
        "                     name=\"conv2_weights\")\n",
        "conv = tf.nn.conv2d(pooled_conv1, kernel, [1, 4, 4, 1], padding=\"SAME\")\n",
        "bias = tf.Variable(tf.truncated_normal([256]), name=\"conv2_bias\")\n",
        "conv_with_bias = tf.nn.bias_add(conv, bias)\n",
        "conv2 = tf.nn.relu(conv_with_bias, name=\"conv2\")\n",
        "lrn2 = tf.nn.lrn(conv2,\n",
        "                 alpha=1e-4,\n",
        "                 beta=0.75,\n",
        "                 depth_radius=2,\n",
        "                 bias=2.0)\n",
        "\n",
        "pooled_conv2 = tf.nn.max_pool(lrn2,\n",
        "                              ksize=[1, 3, 3, 1],\n",
        "                              strides=[1, 2, 2, 1],\n",
        "                              padding=\"SAME\",\n",
        "                              name=\"pool2\")\n",
        "\n",
        "# Third CONV layer\n",
        "kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 384],\n",
        "                                         dtype=tf.float32,\n",
        "                                         stddev=1e-1),\n",
        "                     name=\"conv3_weights\")\n",
        "conv = tf.nn.conv2d(pooled_conv2, kernel, [1, 1, 1, 1], padding=\"SAME\")\n",
        "bias = tf.Variable(tf.truncated_normal([384]), name=\"conv3_bias\")\n",
        "conv_with_bias = tf.nn.bias_add(conv, bias)\n",
        "conv3 = tf.nn.relu(conv_with_bias, name=\"conv3\")\n",
        "\n",
        "# Fourth CONV layer\n",
        "kernel = tf.Variable(tf.truncated_normal([3, 3, 384, 384],\n",
        "                                         dtype=tf.float32,\n",
        "                                         stddev=1e-1),\n",
        "                     name=\"conv4_weights\")\n",
        "conv = tf.nn.conv2d(conv3, kernel, [1, 1, 1, 1], padding=\"SAME\")\n",
        "bias = tf.Variable(tf.truncated_normal([384]), name=\"conv4_bias\")\n",
        "conv_with_bias = tf.nn.bias_add(conv, bias)\n",
        "conv4 = tf.nn.relu(conv_with_bias, name=\"conv4\")\n",
        "\n",
        "# Fifth CONV Layer\n",
        "kernel = tf.Variable(tf.truncated_normal([3, 3, 384, 256],\n",
        "                                         dtype=tf.float32,\n",
        "                                         stddev=1e-1),\n",
        "                     name=\"conv5_weights\")\n",
        "conv = tf.nn.conv2d(conv4, kernel, [1, 1, 1, 1], padding=\"SAME\")\n",
        "bias = tf.Variable(tf.truncated_normal([256]), name=\"conv5_bias\")\n",
        "conv_with_bias = tf.nn.bias_add(conv, bias)\n",
        "conv5 = tf.nn.relu(conv_with_bias, name=\"conv5\")\n",
        "\n",
        "# Fully Connected Layers\n",
        "fc_size = 256\n",
        "conv5 = tf.layers.flatten(conv5) # tf.flatten\n",
        "weights = tf.Variable(tf.truncated_normal([fc_size, fc_size]), name=\"fc1_weights\")\n",
        "bias = tf.Variable(tf.truncated_normal([fc_size]), name=\"fc1_bias\")\n",
        "fc1 = tf.matmul(conv5, weights) + bias\n",
        "fc1 = tf.nn.relu(fc1, name=\"fc1\")\n",
        "\n",
        "weights = tf.Variable(tf.truncated_normal([fc_size, fc_size]), name=\"fc2_weights\")\n",
        "bias = tf.Variable(tf.truncated_normal([fc_size]), name=\"fc2_bias\")\n",
        "fc2 = tf.matmul(fc1, weights) + bias\n",
        "fc2 = tf.nn.relu(fc2, name=\"fc2\")\n",
        "\n",
        "weights = tf.Variable(tf.zeros([fc_size, n_classes]), name=\"output_weight\")\n",
        "bias = tf.Variable(tf.truncated_normal([n_classes]), name=\"output_bias\")\n",
        "out = tf.matmul(fc2, weights) + bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yL5Gs6TxbGo",
        "outputId": "f8956df9-8941-43f2-8e79-a51f202b6acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:86: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZHrozAQ0gHN",
        "outputId": "e8de890f-4510-4162-bf80-89ffba953741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My \\Drive\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf7Tc7N007Xe",
        "outputId": "c30e3476-fcd5-4976-cfd8-6466accbfe0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n",
            " amazon_cells_labelled.txt\n",
            " Analysis.ipynb\n",
            " Assignment7.pdf\n",
            " Assignment_networkanalysis.Rmd\n",
            " cifar-10-batches-py\n",
            "'Colab Notebooks'\n",
            "'Dawid and Musio - 2021 - Effects of Causes and Causes of Effects.pdf'\n",
            " delays.csv\n",
            " final_proj_karan_shreya.ipynb\n",
            "'Final Research Proposal _Shreya Kulkarni.docx'\n",
            " flight_2018.csv\n",
            " haarcascade_frontalface_default.xml\n",
            " higgs-activity_time.txt.gz\n",
            " higgs-mention_network.edgelist.gz\n",
            " higgs-reply_network.edgelist.gz\n",
            " higgs-retweet_network.edgelist.gz\n",
            " higgs-social_network.edgelist.gz\n",
            " imdb_labelled.txt\n",
            " Lab2:Colab\n",
            " Lab3.ipynb\n",
            "'Lab3-ML2 (1).html'\n",
            " Laboratory2.pdf\n",
            "'Laboratory3 (1).pdf'\n",
            " Machine_Learning_DeepLearning_network.ipynb\n",
            "'mnist_cnn (1).py'\n",
            " mnist_cnn.py\n",
            " my_model.h5\n",
            " seg_pred\n",
            " ShreyaKulkarni_ResearchThesisProposal2.pdf\n",
            "'Untitled document.gdoc'\n",
            " yelp_labelled.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mylib.py\n",
        "\n",
        "def MyFunction():\n",
        "  print ('My imported duntion')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mCcIQfb1iJD",
        "outputId": "5aebd7c4-7123-4804-bb22-0ad213b5f157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mylib.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l mylib.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSiDQJa01tmA",
        "outputId": "b8f47253-7e01-4f42-9a58-f6ed8d237e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 52 Nov 12 03:16 mylib.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mylib\n",
        "mylib.MyFunction()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrKQqKN412ZR",
        "outputId": "00bef2d4-9cca-4f78-e3df-9f61f7dfdb00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My imported duntion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TST-9i6L4XR0",
        "outputId": "e1925a66-6558-4630-a0be-b90f9b0d337d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement model (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for model\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from cifar import Cifar\n",
        "tf.keras.datasets.cifar10.load_data()\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "#import models\n",
        "from models import user\n",
        "import helper\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 16\n",
        "no_of_epochs = 10\n",
        "\n",
        "y = tf.placeholder(tf.float32, [None, model.n_classes])\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "    logits=model.out,\n",
        "    labels=y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "correct_pred = tf.equal(tf.argmax(model.out, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "tf.summary.histogram(\"cost\", cost)\n",
        "tf.summary.histogram(\"accuracy\", accuracy)\n",
        "\n",
        "cifar = Cifar(batch_size=batch_size)\n",
        "\n",
        "init = tf.initialize_all_variables()\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "i = 0\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    reader = tf.WholeFileReader()\n",
        "    writer = tf.summary.FileWriter( './logs/', sess.graph)\n",
        "\n",
        "    for epoch in range(no_of_epochs):\n",
        "        for batch in tqdm(cifar.batches,\n",
        "                          desc=\"Epoch {}\".format(epoch),\n",
        "                          unit=\"batch\"):\n",
        "\n",
        "            inp, out = helper.transform_to_input_output(batch, dim=model.n_classes)\n",
        "\n",
        "            sess.run([optimizer],\n",
        "                        feed_dict={\n",
        "                            model.input_images: inp,\n",
        "                            y: out})\n",
        "\n",
        "        merge = tf.summary.merge_all()\n",
        "        acc, loss, summary = sess.run([accuracy, cost, merge],\n",
        "                       feed_dict={\n",
        "                           model.input_images: inp,\n",
        "                           y: out})\n",
        "\n",
        "        writer.add_summary(summary, i)\n",
        "        i = i + 1\n",
        "\n",
        "        print(\"Acc: {} Loss: {}\".format(acc, loss))\n",
        "\n",
        "        inp_test, out_test = helper.transform_to_input_output(cifar.test_set,\n",
        "                                                        dim=model.n_classes)\n",
        "\n",
        "        test_acc = sess.run([accuracy],\n",
        "                feed_dict={\n",
        "                    model.input_images: inp_test,\n",
        "                    y: out_test })\n",
        "        print(\"Test Acc: {}\".format(test_acc))\n",
        "\n",
        "        saver.save(sess, \"saved_model/alexnet.ckpt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "r6z8Sb2yxbLs",
        "outputId": "601f6ea1-116a-4d35-e39c-8e544c094771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-f0a4cb735535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#import models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q8wWWeHGxbOY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}